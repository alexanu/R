
install.packages("xlsx")

library(readr)
library(dplyr)
library(data.table)
library(stringr)
library(xlsx)
library(magrittr)

Nasdaq<-NULL
Nasdaq


Nasdaq <- read.csv("https://indexes.nasdaqomx.com//docs//AppendixNQGIIndexes.csv",stringsAsFactors = FALSE) %>% # the list contains more than 16ths indeces  
          as.data.table() #the data.table::fread function didn't work in the office, hence transformation into data.table is done in 2 steps

Nasdaq<- Nasdaq[Currency=="EUR", # concentrate only on indexes in EUR (Around 2600 indeces)      
                list(Price.Return.Symbol,Index.Name, Geography)] # keeping only needed columns
Nasdaq<- Nasdaq[grep("[0-9]{4}", Price.Return.Symbol)] # leaving only rows, which contain 4-digit code, i.e specific sector
Nasdaq<- Nasdaq[!grepl("LMEUR", Price.Return.Symbol),] # leaving only rows, which don't have "LM" in the name, i.e. no large, med or small capitalization 
Nasdaq<- Nasdaq[!grepl(" Cap ", Index.Name),] # If there is "Cap" in the name, it means the index is focused on certain capitalization. We do not need that => need to exclude
Nasdaq[,Sector.Code:=str_extract(Price.Return.Symbol,"[[:digit:]]{4}")] # new column with 4-digit code sector code
Nasdaq[,Industry.Code:=str_c(str_sub(Sector.Code,1,1),"000")] # for creation of separate column for the broad sector, we need to extract 1st digit from sector and add "000" to it
Nasdaq[,Industry.Code:=str_replace(Industry.Code,"0000","0001")] # Oil & Gas has code 0001
Nasdaq<- Nasdaq[Sector.Code==Industry.Code,] # we will concentrate only on the index for the whole industry, not sub-sectors
Nasdaq[,Sector.Code:= as.integer(Sector.Code),]


############# getting the countries & industry information ######################

id <- "16R4aKHBrmykKpE59Mrt5gClkykJuwTBJ" # The file is taken in Dec 2017 from http://www.ftserussell.com/files/support-documents/icb-rgs-structural-conversion-map
ICB <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id),   sep=";",   stringsAsFactors = FALSE) %>%  
        as.data.table() #the data.table::fread function didn't work in the office, hence transformation into data.table is done in 2 steps  
Industry <- ICB[,.(.N),by=.(Old.ICB.Industry.code, Old.ICB.Industry)]

id_country <- "1EPWUelh1WHwWTlzWAvj-3C_mfdx_dQmZ"
Countries <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id_country),   
                      sep=";",   stringsAsFactors = FALSE,   skip=1) %>%  
             as.data.table() #the data.table::fread function didn't work in the office, hence transformation into data.table is done in 2 steps

############ vlookuping from the google drive tables ############################
setkey(Nasdaq,Sector.Code)
setkey(Industry,Old.ICB.Industry.code)
    Nasdaq<- Nasdaq[Industry,nomatch=0]

setkey(Nasdaq,Geography)
setkey(Countries,Nasdaq.Country.Code) 
    Nasdaq<- Nasdaq[Countries,nomatch=0]

# Could be done like this:
# Nasdaq[Geography %in% Countries$Nasdaq.Country.Code,]
# ... but no additional columns appear. It is just filtering

Nasdaq[,':='(Geography=NULL, Industry.Code=NULL,N=NULL,Name=NULL,ETF.REGION=NULL)] # delete not needed column



Test_Tickers <- Nasdaq[sample(1:nrow(Nasdaq), 10, replace=T),1] %>% # we select 10 random tickers from our list
		    unlist() %>% as.character()
Path_Work <-"L:\\AGCS\\CFO\\Metadata\\For 2013\\Weight table\\"

Path_Work_Short <-"L:/AGCS/CFO/Metadata/For 2013/Weight table/"


End_Date = Sys.Date()-3 # format should be “2015-01-19”
Start_Date = End_Date-7 #format should be “2015-01-19”

as.integer(End_Date-Start_Date)


lapply(Test_Tickers, # for all selected tickers we apply the function "download.file"
	 function(x) download.file(sprintf("https://indexes.nasdaqomx.com/Index/ExportHistory/%s?startDate=%sT00:00:00.000&endDate=%sT00:00:00.000&timeOfDay=EOD.xlsx",
	   						x,Start_Date, End_Date),
					  destfile = paste0(Path_Work,x,".xlsx"),
					 mode="wb"))


----------------------------------------------------------------------------------------------------

file_list <- list.files(path=Path_Work_Short, pattern="*.xlsx") # create list of all .csv files in folder

data <- 
  do.call("rbind", 
          lapply(file_list, 
                 function(x) cbind(
						read.xlsx(paste0(Path_Work_Short, x),
                 				    	    endRow=as.integer(End_Date-Start_Date)-1,
  						          sheetIndex=1,
						          colIndex = c(1, 2)),
					     x)
                 )
          )





--------------------------------------------------------------------------------------------------------------


library(data.table)
DT = do.call(rbind, lapply(files, fread)
# the same using `rbindlist()`
DT = rbindlist(lapply(paste0(Path_Work_Short,Test_Tickers,".csv"), fread))

---------------------------------------------------------
