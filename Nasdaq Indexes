
install.packages("xlsx")

library(readr)
library(dplyr)
library(data.table)
library(stringr)
library(xlsx)
library(magrittr)

Nasdaq<-NULL
Nasdaq


Nasdaq <- read.csv("https://indexes.nasdaqomx.com//docs//AppendixNQGIIndexes.csv",stringsAsFactors = FALSE) %>% # the list contains more than 16ths indeces  
          as.data.table() #the data.table::fread function didn't work in the office, hence transformation into data.table is done in 2 steps

Nasdaq<- Nasdaq[Currency=="EUR", # concentrate only on indexes in EUR (Around 2600 indeces)      
                list(Price.Return.Symbol,Index.Name, Geography)] # keeping only needed columns
Nasdaq<- Nasdaq[grep("[0-9]{4}", Price.Return.Symbol)] # leaving only rows, which contain 4-digit code, i.e specific sector
Nasdaq<- Nasdaq[!grepl("LMEUR", Price.Return.Symbol),] # leaving only rows, which don't have "LM" in the name, i.e. no large, med or small capitalization 
Nasdaq<- Nasdaq[!grepl(" Cap ", Index.Name),] # If there is "Cap" in the name, it means the index is focused on certain capitalization. We do not need that => need to exclude
Nasdaq[,Sector.Code:=str_extract(Price.Return.Symbol,"[[:digit:]]{4}")] # new column with 4-digit code sector code
Nasdaq[,Industry.Code:=str_c(str_sub(Sector.Code,1,1),"000")] # for creation of separate column for the broad sector, we need to extract 1st digit from sector and add "000" to it
Nasdaq[,Industry.Code:=str_replace(Industry.Code,"0000","0001")] # Oil & Gas has code 0001
Nasdaq<- Nasdaq[Sector.Code==Industry.Code,] # we will concentrate only on the index for the whole industry, not sub-sectors
Nasdaq[,Sector.Code:= as.integer(Sector.Code),]


############# getting the countries & industry information ######################

id <- "16R4aKHBrmykKpE59Mrt5gClkykJuwTBJ" # The file is taken in Dec 2017 from http://www.ftserussell.com/files/support-documents/icb-rgs-structural-conversion-map
ICB <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id),   sep=";",   stringsAsFactors = FALSE) %>%  
        as.data.table() #the data.table::fread function didn't work in the office, hence transformation into data.table is done in 2 steps  
Industry <- ICB[,.(.N),by=.(Old.ICB.Industry.code, Old.ICB.Industry)]

id_country <- "1EPWUelh1WHwWTlzWAvj-3C_mfdx_dQmZ"
Countries <- read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", id_country),   
                      sep=";",   stringsAsFactors = FALSE,   skip=1) %>%  
             as.data.table() #the data.table::fread function didn't work in the office, hence transformation into data.table is done in 2 steps

############ vlookuping from the google drive tables ############################
setkey(Nasdaq,Sector.Code)
setkey(Industry,Old.ICB.Industry.code)
    Nasdaq<- Nasdaq[Industry,nomatch=0]

setkey(Nasdaq,Geography)
setkey(Countries,Nasdaq.Country.Code) 
    Nasdaq<- Nasdaq[Countries,nomatch=0]

# Could be done like this:
# Nasdaq[Geography %in% Countries$Nasdaq.Country.Code,]
# ... but no additional columns appear. It is just filtering

Nasdaq[,':='(Geography=NULL, Industry.Code=NULL,N=NULL,Name=NULL,ETF.REGION=NULL)] # delete not needed column






head(Nasdaq)
Nasdaq[sample(1:nrow(Nasdaq), 1),1]
as.character(Nasdaq[1,1])
sapply(Nasdaq, class)




#Indexes <- c("NQG1300EUR", "NQFR8000EUR", "NQEURO2000EUR")
Indexes <- c("NQG1300EUR")
End_Date = Sys.Date()-3 # format should be “2015-01-19”
Start_Date = End_Date-7 #format should be “2015-01-19”
URL_Nasdaq <- paste0("https://indexes.nasdaqomx.com/Index/ExportHistory/",
                      Nasdaq[sample(1:nrow(Nasdaq), 1),1],
                      "?startDate=",
                      Start_Date, 
                      "T00:00:00.000&endDate=",
                      End_Date,
                        "T00:00:00.000&timeOfDay=EOD.xlsx") # URL for all nasdaq indexes

URL_Nasdaq
	


------------------------------------------------------
library(readr)
library(dplyr)
tbl = lapply(URL_Nasdaq, read_csv) %>% bind_rows()

install.packages("XLConnect")
library(XLConnect)

library()
search()
read_excel(URL_Nasdaq, sheet = "History")
y <- read.xlsx(URL_Nasdaq,sheet = "History")
fread(URL_Nasdaq)

tmp = tempfile(fileext = ".xlsx")
read.xlsx(download.file(URL_Nasdaq, destfile = tempfile(fileext = ".xlsx"), mode="wb"),1)
WorksheetFromFile(file = tmp, sheet = 1)

readWorksheet(URL_Nasdaq, sheet = 1)
readWorksheet

x <- loadWorkbook(URL_Nasdaq)
b <- XLConnect::readWorksheet(URL_Nasdaq, sheet=1)


install.packages("rio")
library(rio)
import(URL_Nasdaq)



---------------------------------


Test_Tickers <- Nasdaq[sample(1:nrow(Nasdaq), 10, replace=T),1] %>% # we select 10 random tickers from our list
		    unlist() %>% as.character()


Path_Work <-"L:\\AGCS\\CFO\\Metadata\\For 2013\\Weight table\\"
End_Date = Sys.Date()-3 # format should be “2015-01-19”
Start_Date = End_Date-7 #format should be “2015-01-19”

URL_Nasdaq <- 



lapply(Test_Tickers, # for all selected tickers we apply the function "download.file"
	 function(x) download.file(sprintf("https://indexes.nasdaqomx.com/Index/ExportHistory/%s?startDate=%sT00:00:00.000&endDate=%sT00:00:00.000&timeOfDay=EOD.xlsx",
	   						x,Start_Date, End_Date),
					  destfile = paste0(Path_Work,x,".csv"),
					 mode="wb"))


lapply(Test_Tickers, # for all selected tickers we apply the function "download.file"
	 function(x) read.csv(download.file(sprintf("https://indexes.nasdaqomx.com/Index/ExportHistory/%s?startDate=%sT00:00:00.000&endDate=%sT00:00:00.000&timeOfDay=EOD.xlsx",
	   						x,Start_Date, End_Date),
					  destfile = paste0(Path_Work,x,".csv"),
					 mode="wb")))
read.csv(paste0(Path_Work,Test_Tickers,".csv"))
paste0(Path_Work,Test_Tickers,".csv")


download.file


---------------------------------------------------------

library(data.table)
DT = do.call(rbind, lapply(files, fread)
# the same using `rbindlist()`
DT = rbindlist(lapply(files, fread))

---------------------------------------------------------
